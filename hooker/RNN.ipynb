{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(base_dir+'train_1.csv', nrows=100)\n",
    "dates = [c for c in full_df.columns if c !='Page']\n",
    "val_dates = dates[-61:]\n",
    "val = full_df[['Page']+val_dates]\n",
    "train = full_df.drop(val_dates, axis=1)\n",
    "filled_train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = filled_train.drop('Page', axis=1).values\n",
    "y = val.fillna(0).drop('Page', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 489) (100, 61)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocessing\n",
    " * scale each time series to have 0 mean and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 489)\n",
      "(100, 489, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.010761664611856"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = StandardScaler()\n",
    "# discussion on which scaler to use here: https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/38274\n",
    "# each ts should have 0 mean and unit variance\n",
    "# since the time series are the 'features' being scaled, transpose first\n",
    "X = scaler.fit_transform(X.T).T\n",
    "print(X.shape)\n",
    "assert(np.isclose(np.mean(X[0]),0))\n",
    "# input shape: samples, timesteps, features\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "print(X.shape)\n",
    "np.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEFAULT_SEED = 123456\n",
    "n_pred = 60 # number of values to predict\n",
    "n_cond = 60 # number of values to condition on\n",
    "\n",
    "class DataProvider(object):\n",
    "    \"\"\"Generic data provider.\"\"\"\n",
    "\n",
    "    def __init__(self, inputs, targets, batch_size, max_num_batches=-1,\n",
    "                 shuffle_order=True, rng=None):\n",
    "        \"\"\"Create a new data provider object.\n",
    "\n",
    "        Args:\n",
    "            inputs (ndarray): Array of data input features of shape\n",
    "                (num_data, input_dim).\n",
    "            targets (ndarray): Array of data output targets of shape\n",
    "                (num_data, output_dim) or (num_data,) if output_dim == 1.\n",
    "            batch_size (int): Number of data points to include in each batch.\n",
    "            max_num_batches (int): Maximum number of batches to iterate over\n",
    "                in an epoch. If `max_num_batches * batch_size > num_data` then\n",
    "                only as many batches as the data can be split into will be\n",
    "                used. If set to -1 all of the data will be used.\n",
    "            shuffle_order (bool): Whether to randomly permute the order of\n",
    "                the data before each epoch.\n",
    "            rng (RandomState): A seeded random number generator.\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        if batch_size < 1:\n",
    "            raise ValueError('batch_size must be >= 1')\n",
    "        self._batch_size = batch_size\n",
    "        if max_num_batches == 0 or max_num_batches < -1:\n",
    "            raise ValueError('max_num_batches must be -1 or > 0')\n",
    "        self._max_num_batches = max_num_batches\n",
    "        self._update_num_batches()\n",
    "        self.shuffle_order = shuffle_order\n",
    "        self._current_order = np.arange(inputs.shape[0])\n",
    "        if rng is None:\n",
    "            rng = np.random.RandomState(DEFAULT_SEED)\n",
    "        self.rng = rng\n",
    "        self.new_epoch()\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        \"\"\"Number of data points to include in each batch.\"\"\"\n",
    "        return self._batch_size\n",
    "\n",
    "    @batch_size.setter\n",
    "    def batch_size(self, value):\n",
    "        if value < 1:\n",
    "            raise ValueError('batch_size must be >= 1')\n",
    "        self._batch_size = value\n",
    "        self._update_num_batches()\n",
    "\n",
    "    @property\n",
    "    def max_num_batches(self):\n",
    "        \"\"\"Maximum number of batches to iterate over in an epoch.\"\"\"\n",
    "        return self._max_num_batches\n",
    "\n",
    "    @max_num_batches.setter\n",
    "    def max_num_batches(self, value):\n",
    "        if value == 0 or value < -1:\n",
    "            raise ValueError('max_num_batches must be -1 or > 0')\n",
    "        self._max_num_batches = value\n",
    "        self._update_num_batches()\n",
    "\n",
    "    def _update_num_batches(self):\n",
    "        \"\"\"Updates number of batches to iterate over.\"\"\"\n",
    "        # maximum possible number of batches is equal to number of whole times\n",
    "        # batch_size divides in to the number of data points which can be\n",
    "        # found using integer division\n",
    "        possible_num_batches = self.inputs.shape[0] // self.batch_size\n",
    "        if self.max_num_batches == -1:\n",
    "            self.num_batches = possible_num_batches\n",
    "        else:\n",
    "            self.num_batches = min(self.max_num_batches, possible_num_batches)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Implements Python iterator interface.\n",
    "\n",
    "        This should return an object implementing a `next` method which steps\n",
    "        through a sequence returning one element at a time and raising\n",
    "        `StopIteration` when at the end of the sequence. Here the object\n",
    "        returned is the DataProvider itself.\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def new_epoch(self):\n",
    "        \"\"\"Starts a new epoch (pass through data), possibly shuffling first.\"\"\"\n",
    "        self._curr_batch = 0\n",
    "        if self.shuffle_order:\n",
    "            self.shuffle()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the provider to the initial state.\"\"\"\n",
    "        inv_perm = np.argsort(self._current_order)\n",
    "        self._current_order = self._current_order[inv_perm]\n",
    "        self.inputs = self.inputs[inv_perm]\n",
    "        self.targets = self.targets[inv_perm]\n",
    "        self.new_epoch()\n",
    "\n",
    "    def shuffle(self):\n",
    "        \"\"\"Randomly shuffles order of data.\"\"\"\n",
    "        perm = self.rng.permutation(self.inputs.shape[0])\n",
    "        self._current_order = self._current_order[perm]\n",
    "        self.inputs = self.inputs[perm]\n",
    "        self.targets = self.targets[perm]\n",
    "        if hasattr(self, 'track_ids'):\n",
    "            self.track_ids = self.track_ids[perm]\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"Returns next data batch or raises `StopIteration` if at end.\"\"\"\n",
    "        if self._curr_batch + 1 > self.num_batches:\n",
    "            # no more batches in current iteration through data set so start\n",
    "            # new epoch ready for another pass and indicate iteration is at end\n",
    "            self.new_epoch()\n",
    "            raise StopIteration()\n",
    "        # create an index slice corresponding to current batch number\n",
    "        batch_slice = slice(self._curr_batch * self.batch_size,\n",
    "                            (self._curr_batch + 1) * self.batch_size)\n",
    "        inputs_batch = self.inputs[batch_slice]\n",
    "        targets_batch = self.targets[batch_slice]\n",
    "        self._curr_batch += 1\n",
    "        return inputs_batch, targets_batch\n",
    "\n",
    "    # Python 3.x compatibility\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "class MultiTSDataProvider(DataProvider):\n",
    "    \n",
    "    def __init__(self, which_set='train', batch_size=100, max_num_batches=-1,\n",
    "                 shuffle_order=True, rng=None, n_pred=60, n_cond=60, stride_length=10,\n",
    "                 scaler=StandardScaler(), base_dir = '../data/', n_ts=100):\n",
    "        self.n_pred = n_pred # number of values to predict\n",
    "        self.n_cond = n_cond # number of values on which to condition predictions\n",
    "        full_df = pd.read_csv(base_dir+'train_1.csv', nrows=n_ts)\n",
    "        dates = [c for c in full_df.columns if c !='Page']\n",
    "        val_dates = dates[-(n_pred+n_cond):]\n",
    "        self.val_dates = val_dates\n",
    "        if which_set == 'train':\n",
    "            inputs = full_df.drop(['Page'] + val_dates, axis=1).fillna(0).values\n",
    "        elif which_set == 'val':\n",
    "            inputs = full_df[val_dates].fillna(0).values\n",
    "          # each ts should have 0 mean and unit variance\n",
    "        if scaler:\n",
    "            # need to change the way this behaves\n",
    "            inputs = scaler.fit_transform(inputs)\n",
    "            print(np.max(inputs))\n",
    "        print(inputs.shape)\n",
    "        \n",
    "        if which_set == 'train':\n",
    "            \n",
    "            window_length = n_cond + n_pred\n",
    "            if stride_length > 0:\n",
    "                n_windows = int(np.floor(np.divide(inputs.shape[1] - window_length,\n",
    "                                                   stride_length) + 1))\n",
    "                start_index = 0\n",
    "                window_array = np.ndarray((inputs.shape[0], n_windows, window_length))\n",
    "                for i in range(n_windows):\n",
    "                    window_array[:,i,:] = inputs[:, start_index:start_index+window_length]\n",
    "                    start_index += stride_length\n",
    "                print(window_array.shape)\n",
    "                window_array = window_array.reshape((-1,window_length,1))\n",
    "                print(window_array.shape)\n",
    "                print('{} overlapping windows of length {} in training date range'.format(n_windows, window_length))\n",
    "            #         inputs = w.reshape((-1, window_length, inputs.shape[-1])) # reshape inputs to (n_sample, length, n_features)\n",
    "                targets = window_array[:,self.n_cond:,:] # shifted one along from inputs - so there is one target val which is never input, into either decoder or encoder\n",
    "                inputs = np.pad(window_array[:,:-1,:],((0,0), (1,0), (0,0)),mode='constant')\n",
    "            \n",
    "            elif stride_length == -1:\n",
    "                inputs = inputs[:,-window_length:]\n",
    "                targets = inputs[:, self.n_cond:]\n",
    "                inputs = np.pad(inputs[:,:self.n_cond], ((0,0),(1,n_pred-1)), mode='constant')\n",
    "\n",
    "        #         inputs, targets = inputs[:,:self.n_cond,:], inputs[:,self.n_cond:,:]\n",
    "            inputs = inputs.reshape((inputs.shape[0], -1))\n",
    "            targets = targets.reshape((targets.shape[0], -1))\n",
    "        \n",
    "        elif which_set == 'val':\n",
    "            targets = inputs[:, self.n_cond:]\n",
    "            inputs = np.pad(inputs[:,:self.n_cond], ((0,0), (1,n_pred-1)), mode='constant') # decoder inputs is now 1 useful num followed by a bunch of zeros, in principle\n",
    "        \n",
    "        print(inputs.shape, targets.shape)\n",
    "        super(MultiTSDataProvider, self).__init__(\n",
    "            inputs, targets, batch_size, max_num_batches, shuffle_order, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.86570145996\n",
      "(100, 430)\n",
      "(100, 32, 120)\n",
      "(3200, 120, 1)\n",
      "32 overlapping windows of length 120 in training date range\n",
      "(3200, 120) (3200, 60)\n",
      "9.62122286284\n",
      "(100, 120)\n",
      "(100, 120) (100, 60)\n",
      "example validation decoder input: \n",
      " [-0.33158052  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.        ] example targets: \n",
      " [-0.3553055  -0.27947026 -0.31877014 -0.43816989 -0.42333603 -0.5669012\n",
      "  0.31659855 -0.32265966 -0.15909011 -0.24014955 -0.3393971  -0.47004148\n",
      " -0.33085582 -0.06996927 -0.41012705 -0.26484717 -0.17938759 -0.5097515\n",
      " -0.51362105 -0.18910207 -0.32819227 -0.41757335  0.78273372 -0.49678511\n",
      " -0.44061377 -0.37982779 -0.23275741 -0.17345243 -0.28053388 -0.28363826\n",
      " -0.20579917 -0.46789421 -0.22058082 -0.12804302  0.15186823 -0.26225733\n",
      " -0.12785377 -0.28021776 -0.30720629 -0.31169985 -0.31079292 -0.42547127\n",
      " -0.20906644 -0.33502424  3.0846121  -0.28965812 -0.25076344  0.6329489\n",
      "  0.35031622  6.08307119 -0.47738382 -0.46901344 -0.18069436  0.38620477\n",
      " -0.1575384   0.1450194   1.05137933 -0.06231434 -0.39480872 -0.33889362] example inputs: \n",
      " [  0.00000000e+00  -4.95692415e-01  -2.34635744e-01  -1.89031164e-01\n",
      "   7.76597224e-01   7.55807109e+00   3.02724451e-01  -3.29340430e-01\n",
      "  -4.90387770e-01  -4.19287869e-01  -1.35904032e-01  -3.97493088e-03\n",
      "  -1.52603662e-01  -2.00461114e-01  -2.43524948e-01  -1.88324748e-01\n",
      "  -3.34188994e-01  -7.78243531e-01   9.61545877e-01  -3.40969793e-01\n",
      "   1.24757043e-02  -1.73593751e-01  -2.64120261e-02  -3.32504581e-01\n",
      "   4.44377448e-02  -2.62954327e-01   2.20325929e-01  -3.86876615e-01\n",
      "  -1.37156087e-01  -1.94499783e-01  -1.48629586e-01  -3.01399214e-01\n",
      "   2.51499892e-02  -2.52588624e-01  -4.42497123e-01  -2.07514852e-01\n",
      "  -4.88068634e-01  -1.50918643e-01  -3.38958208e-01  -2.02178016e-01\n",
      "   1.02654074e+00  -4.56550726e-01   5.01248473e-04  -3.98316727e-01\n",
      "  -3.76914350e-01  -3.37991574e-01  -2.99607841e-01   4.97481734e-01\n",
      "  -1.96820539e-01  -2.48104028e-01  -2.55309318e-01  -1.66524814e-01\n",
      "  -3.92712460e-01  -8.14623425e-02  -2.53167059e-01  -3.35214716e-01\n",
      "  -2.58417156e-01  -2.16887843e-01  -3.82770283e-01  -3.72362919e-01]\n"
     ]
    }
   ],
   "source": [
    "train_data = MultiTSDataProvider(scaler=StandardScaler())\n",
    "val_data = MultiTSDataProvider(scaler=StandardScaler(), which_set='val')\n",
    "a = train_data.next()[0]\n",
    "np.max(a)\n",
    "inps, targs = val_data.next()\n",
    "\n",
    "print('example validation decoder input: \\n', inps[0][n_cond:],\n",
    "      'example targets: \\n', targs[0][:],\n",
    "      'example inputs: \\n', inps[0][:n_cond])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function:\n",
    "\n",
    "Modified SMAPE. Note that using MAE gives not much different results, but easier and faster to train, so I recommend MAE for starters. (https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/38337)\n",
    "\n",
    "### Output:\n",
    "\n",
    "You can predict one day, refit the model with previous days + predicted day, predict next day, etc, but it would be too slow and inefficient. The real power of RNN's is that you can build generative model, and predict all 60 days at once. (https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/38337)\n",
    "\n",
    "ONLY PREDICT VALUES FOR A SINGLE TIME SERIES AT ONCE (c.f. the neural network eqn. 1 which outputs hidden rnn states for a single time series at a time, which are then combined to form the joint likelihood above) - DIFFERENT TIME SERIES ARE USED TO GENERATE DIFFERENT TRAINING EXAMPLES; SINGLE MODEL IS TRAINED ON ALL OF THEM.\n",
    "\n",
    "a substantial amount\n",
    "of data on past behavior of similar, related time series can be leveraged for making a forecast for an\n",
    "individual time series. Using data from related time series not only allows fitting more complex (and\n",
    "hence potentially more accurate) models without overfitting\n",
    "\n",
    "https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n",
    "\n",
    "Simplest model is probably some kind of ar\n",
    "\n",
    "running predictions forward with keras: http://www.jakob-aungiers.com/articles/a/LSTM-Neural-Network-for-Time-Series-Prediction, https://machinelearningmastery.com/how-to-use-an-encoder-decoder-lstm-to-echo-sequences-of-random-integers/. the crucial thing that makes sequence to sequence appropriate is: Information about the observations in the conditioning range zi,1:t0−1 is transferred to the prediction\n",
    "range through the initial state hi,t0−1. In the sequence-to-sequence setup, this initial state is the output\n",
    "of an encoder network. Also the two sequences may be of different lengths.\n",
    "\n",
    "### Training examples\n",
    " \n",
    "Secondly, due to the imbalance in the data, a stochastic optimization procedure that picks training\n",
    "instances uniformly at random will visit the small number time series with a large scale very infrequently,\n",
    "which result in underfitting those time series. This could be especially problematic in the\n",
    "demand forecasting setting, where high-velocity items can exhibit qualitatively different behavior\n",
    "than low-velocity items, and having an accurate forecast for high-velocity items might be more important\n",
    "for meeting certain business objectives. To counteract this effect, we sample the examples\n",
    "non-uniformly during training. In particular, in our weighted sampling scheme, the probability of\n",
    "selecting a window from an example with scale νi is proportional to νi.\n",
    "\n",
    "### Tensorflow seq2seq\n",
    "[github seq2seq helpers](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py)\n",
    "[ex. model built using above](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py)\n",
    "[keras lib](https://github.com/farizrahman4u/seq2seq)\n",
    "[new api (1.3) seq2seq](https://medium.com/@ilblackdragon/tensorflow-sequence-to-sequence-3d9d2e238084)\n",
    "[seq2seq expts](https://github.com/raindeer/seq2seq_experiments/blob/master/model.py#L81)\n",
    "* use tied_rnn_seq2seq if using tf\n",
    "* will need to write custom loss func\n",
    "* not sure the keras library will work because although we are sort of using encoder-decoder, we're not really outputting a 'context vector', just transferring the hidden state\n",
    "* to pass predicted values in as inputs when decoding: https://stackoverflow.com/questions/38050333/how-to-predict-a-simple-sequence-using-seq2seq-from-tensorflow (although there is an option just to use the true values during training, which is what the amazon paper does).\n",
    "\n",
    "The initial state\n",
    "of the encoder hi,0 as well as zi,0 are initialized to zero\n",
    "\n",
    "The basic rnn seq2seq works by making a copy of the cell (set of lstm units), and using two separate copies, one for encoder and one for decoder, with different weights. Tied rnn seq2seq  uses a single copy, ensuring weights are shared.\n",
    "\n",
    "### Validation Data\n",
    "\n",
    "Should be normalized in the same way as training data (i.e. using statistics from the training data). But this doesn't really make sense - there's no shared features. So phaps just normalize validation inputs (not targets) in the same way that training inputs are normalized.\n",
    "\n",
    "The Amazon paper suggests scaling by the average value\n",
    "\n",
    "$v_i = 1  + \\sum_{t=0}^{t_0} z_{i,t}$\n",
    "\n",
    "where $t_0$ is the last conditioning timestep: i.e. we normalize on the conditioning period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "print('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.legacy_seq2seq import tied_rnn_seq2seq\n",
    "hidden_dim = 100\n",
    "output_dim = 1\n",
    "input_dim = 1\n",
    "layers_stacked_count = 2\n",
    "n_cond = 60\n",
    "n_pred = 60\n",
    "learning_rate = 0.007\n",
    "lr_decay = 0.92 \n",
    "momentum = 0.5\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# sess.close()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "with tf.variable_scope('Seq2seq'):\n",
    "\n",
    "    train = tf.placeholder(tf.bool)\n",
    "    # Encoder: inputs\n",
    "    enc_inp = [\n",
    "        tf.placeholder(tf.float32, shape=(None, input_dim), name=\"inp_{}\".format(t))\n",
    "           for t in range(n_cond)\n",
    "    ]\n",
    "\n",
    "    # Decoder: expected outputs\n",
    "    expected_sparse_output = [\n",
    "        tf.placeholder(tf.float32, shape=(None, output_dim), name=\"expected_sparse_output_\".format(t))\n",
    "          for t in range(n_pred)\n",
    "    ]\n",
    "\n",
    "    go_sym = tf.placeholder(tf.float32, shape=(None, output_dim), name=\"GO\")\n",
    "\n",
    "    # Give a \"GO\" token to the decoder. \n",
    "    # You might want to revise what is the appended value \"+ enc_inp[:-1]\". \n",
    "#     dec_inp = [ tf.zeros_like(enc_inp[0], dtype=np.float32, name=\"GO\") ] + [tf.zeros_like(v) for v in enc_inp[:-1]]\n",
    "#     dec_inp = [ tf.zeros_like(enc_inp[0], dtype=np.float32, name=\"GO\")] + enc_inp[1:]\n",
    "    dec_inp = [go_sym] + expected_sparse_output[:-1] # feed previous target as next input\n",
    "\n",
    "    # Create a `layers_stacked_count` of stacked RNNs (GRU cells here). \n",
    "    cells = []\n",
    "    for i in range(layers_stacked_count):\n",
    "        with tf.variable_scope('RNN_{}'.format(i)):\n",
    "            cells.append(tf.nn.rnn_cell.GRUCell(hidden_dim))\n",
    "            # cells.append(tf.nn.rnn_cell.BasicLSTMCell(...))\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "\n",
    "    # For reshaping the input and output dimensions of the seq2seq RNN: \n",
    "    w_out = tf.Variable(tf.random_normal([hidden_dim, output_dim]))\n",
    "    b_out = tf.Variable(tf.random_normal([output_dim]))\n",
    "\n",
    "    output_scale_factor = tf.Variable(1.0, name=\"Output_ScaleFactor\")\n",
    "    def looper(output, i):\n",
    "        return output_scale_factor * (tf.matmul(output, w_out) + b_out)\n",
    "\n",
    "    dec_outputs, dec_memory = tf.cond(train, lambda: tied_rnn_seq2seq(enc_inp, dec_inp, cell),\n",
    "                                      lambda: tied_rnn_seq2seq(enc_inp, dec_inp, cell, loop_function=looper))\n",
    "    # but without the \"norm\" part of batch normalization hehe. \n",
    "    reshaped_outputs = [output_scale_factor*(tf.matmul(i, w_out) + b_out) for i in dec_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('Loss'):\n",
    "    output_loss = 0\n",
    "    for _y, _Y in zip(reshaped_outputs, expected_sparse_output):\n",
    "#         output_loss += tf.reduce_mean(tf.nn.l2_loss(_y - _Y))\n",
    "        output_loss += tf.reduce_mean(tf.abs(_y - _Y)) # average loss across batch for single timestep\n",
    "    loss = output_loss\n",
    "with tf.variable_scope('Optimizer'):\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate, decay=lr_decay, momentum=momentum)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class clock(object):\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        \n",
    "    def __exit__(self, x,y,z):\n",
    "        end = time.time()\n",
    "        print('Elapsed time {} seconds'.format(end-self.start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173.041590529\n",
      "(30000, 430)\n",
      "(30000, 6, 120)\n",
      "(180000, 120, 1)\n",
      "6 overlapping windows of length 120 in training date range\n",
      "(180000, 120) (180000, 60)\n",
      "172.417782586\n",
      "(30000, 120)\n",
      "(30000, 120) (30000, 60)\n",
      "None\n",
      "Elapsed time 0.006696224212646484 seconds\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Operation 'Optimizer/RMSProp' type=NoOp> cannot be interpreted as a Tensor. (Operation name: \"Optimizer/RMSProp\"\nop: \"NoOp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/Variable/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/Variable_1/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/Output_ScaleFactor/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_0/gru_cell/gates/kernel/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_0/gru_cell/gates/bias/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_0/gru_cell/candidate/kernel/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_0/gru_cell/candidate/bias/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_1/gru_cell/gates/kernel/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_1/gru_cell/gates/bias/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_1/gru_cell/candidate/kernel/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_1/gru_cell/candidate/bias/ApplyRMSProp\"\n is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/basev1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    266\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 267\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    268\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basev1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2583\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basev1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2667\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2668\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Operation %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2669\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation name: \"Optimizer/RMSProp\"\nop: \"NoOp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/Variable/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/Variable_1/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/Output_ScaleFactor/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_0/gru_cell/gates/kernel/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_0/gru_cell/gates/bias/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_0/gru_cell/candidate/kernel/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_0/gru_cell/candidate/bias/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_1/gru_cell/gates/kernel/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_1/gru_cell/gates/bias/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_1/gru_cell/candidate/kernel/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_1/gru_cell/candidate/bias/ApplyRMSProp\"\n is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7cea83a5ef8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexpected_sparse_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0merrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mmean_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_cond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basev1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basev1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m--> 984\u001b[0;31m         self._graph, fetches, feed_dict_string, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basev1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \"\"\"\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basev1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basev1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \"\"\"\n\u001b[1;32m    336\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basev1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \"\"\"\n\u001b[1;32m    336\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basev1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m~/miniconda3/envs/basev1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 274\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    275\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Operation 'Optimizer/RMSProp' type=NoOp> cannot be interpreted as a Tensor. (Operation name: \"Optimizer/RMSProp\"\nop: \"NoOp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/Variable/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/Variable_1/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/Output_ScaleFactor/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_0/gru_cell/gates/kernel/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_0/gru_cell/gates/bias/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_0/gru_cell/candidate/kernel/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_0/gru_cell/candidate/bias/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_1/gru_cell/gates/kernel/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_1/gru_cell/gates/bias/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_1/gru_cell/candidate/kernel/ApplyRMSProp\"\ninput: \"^Optimizer/RMSProp/update_Seq2seq/combined_tied_rnn_seq2seq/tied_rnn_seq2seq/multi_rnn_cell/cell_1/gru_cell/candidate/bias/ApplyRMSProp\"\n is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "ts = int(time.time())\n",
    "model_dir = 'checkpoints/{}'.format(ts)\n",
    "os.mkdir(model_dir)\n",
    "n_ts = 30000\n",
    "\n",
    "stride_length = n_cond\n",
    "train_data = MultiTSDataProvider(n_ts=n_ts, scaler=StandardScaler(),\n",
    "                                 n_cond=n_cond, n_pred=n_pred, stride_length=stride_length,\n",
    "                                 batch_size=1024)\n",
    "val_data = MultiTSDataProvider(n_ts=n_ts, scaler=StandardScaler(), which_set='val',\n",
    "                               n_cond=n_cond, n_pred=n_pred,\n",
    "                               batch_size=1024)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "print(sess.run(tf.global_variables_initializer()))\n",
    "errs = []\n",
    "epochs = 15\n",
    "for e in range(epochs):\n",
    "    running_error = 0.\n",
    "    val_error = 0.\n",
    "    mean_running_error = 0.\n",
    "    with clock():\n",
    "        for input_batch, target_batch in train_data:\n",
    "        #     print(input_batch.shape, target_batch.shape)\n",
    "            feed_dict = {train: True}\n",
    "            # each decoder input is batch size x 1\n",
    "            for i in range(n_cond):\n",
    "                feed_dict[enc_inp[i].name] = input_batch[:,i].reshape(-1,1)\n",
    "            feed_dict[go_sym] = input_batch[:, n_cond].reshape(-1,1)\n",
    "            for i in range(n_pred):\n",
    "                feed_dict[expected_sparse_output[i].name] = target_batch[:,i].reshape(-1,1)\n",
    "            _, err = sess.run([train_op, loss], feed_dict=feed_dict)\n",
    "            errs.append(err)\n",
    "            mean_preds = np.mean(input_batch[:,:n_cond], axis=1).reshape(-1,1)\n",
    "        #         print(mean_preds.shape, target_batch.shape)\n",
    "            mean_errs = np.abs(mean_preds - target_batch)\n",
    "        #         print(mean_errs.shape)\n",
    "            batch_mean_err = np.sum(np.mean(mean_errs, axis=0))\n",
    "            running_error += err\n",
    "            mean_running_error += batch_mean_err\n",
    "        running_error /= train_data.num_batches\n",
    "        mean_running_error /= train_data.num_batches\n",
    "        saver.save(sess, model_dir+'/model.ckpt'.format(ts), global_step=e+1)\n",
    "    for input_batch, target_batch in val_data:\n",
    "        feed_dict = {train: False}\n",
    "        for i in range(n_cond):\n",
    "            feed_dict[enc_inp[i].name] = input_batch[:,i].reshape(-1,1)\n",
    "        for i in range(n_pred):\n",
    "            feed_dict[expected_sparse_output[i].name] = target_batch[:,i].reshape(-1,1)\n",
    "        feed_dict[go_sym] = input_batch[:, n_cond].reshape(-1,1)\n",
    "        val_err = sess.run(loss, feed_dict=feed_dict)\n",
    "        # this time we don't need to feed in either decoder_inputs or targets\n",
    "        val_error += val_err\n",
    "    val_error /= val_data.num_batches\n",
    "    print(\"\"\"End of epoch {0}: running error average = {1:.3f}\\n\n",
    "             mean error average = {2:.3f}\\n\n",
    "             val error average = {3:.3f}\"\"\".format(e + 1, running_error, mean_running_error, val_error))\n",
    "# print(len(preds), preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sanity check:\n",
    "\n",
    " * Look at (plot) trained model's predictions from a few out of training sample time series (compare plot after just training on one batch to after a full training run).\n",
    "\n",
    "* Look at SMAPE on val set\n",
    "\n",
    "(NOT GOOD IDEA: Plot multiple sets of predictions for a single time series to verify that the RNN is acting as a generative model in a sensible (random) way - NO THE CURRENT MODEL IS DETERMINISTIC, TO MAKE A PROBABILISTIC MODEL I WOULD HAVE TO OUTPUT PROBABILITIES/PARAMETERS OF A PROBABILITY DISTRIBUTION RATHER THAN ACTUAL VALUES.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_data = MultiTSDataProvider(n_ts=200, scaler=None, which_set='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 120), (200, 60))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.inputs.shape, val_data.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x120b00a58>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120b00940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v_seq = val_data.inputs[190:,:]\n",
    "v_targs = val_data.targets[190:,:]\n",
    "\n",
    "single_s = v_seq[9,:]\n",
    "single_ts = v_targs[9,:]\n",
    "\n",
    "plt.plot(range(len(single_s)), single_s)\n",
    "plt.plot([n_cond + 1 + i for i in range(len(single_ts))], single_ts)\n",
    "# def predict_sequence(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_dict = {train: False}\n",
    "for i in range(n_cond):\n",
    "    feed_dict[encoder_inputs[i].name] = v_seq[:,i].reshape(-1,1)\n",
    "for i in range(n_pred):\n",
    "    feed_dict[targets[i].name] = v_targs[:,i]\n",
    "for i in range(n_pred):\n",
    "    feed_dict[decoder_inputs[i].name] = v_seq[:,i].reshape(-1,1)\n",
    "pred_err, pred_vals = sess.run([mae, preds], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29.966311,\n",
       " 30.700642,\n",
       " 30.565092,\n",
       " 30.607529,\n",
       " 30.699869,\n",
       " 30.820126,\n",
       " 30.955162,\n",
       " 31.09614,\n",
       " 31.237381,\n",
       " 31.375389,\n",
       " 31.508165,\n",
       " 31.634653,\n",
       " 31.754412,\n",
       " 31.867376,\n",
       " 31.973694,\n",
       " 32.073643,\n",
       " 32.167557,\n",
       " 32.255798,\n",
       " 32.338726,\n",
       " 32.416702,\n",
       " 32.490063,\n",
       " 32.559128,\n",
       " 32.62418,\n",
       " 32.685505,\n",
       " 32.743351,\n",
       " 32.797951,\n",
       " 32.849522,\n",
       " 32.898258,\n",
       " 32.944344,\n",
       " 32.987946,\n",
       " 33.029221,\n",
       " 33.06831,\n",
       " 33.10535,\n",
       " 33.140461,\n",
       " 33.173756,\n",
       " 33.205341,\n",
       " 33.235317,\n",
       " 33.263775,\n",
       " 33.290802,\n",
       " 33.316467,\n",
       " 33.340855,\n",
       " 33.364029,\n",
       " 33.386059,\n",
       " 33.40699,\n",
       " 33.426895,\n",
       " 33.44582,\n",
       " 33.463806,\n",
       " 33.480904,\n",
       " 33.497154,\n",
       " 33.512589,\n",
       " 33.527245,\n",
       " 33.541161,\n",
       " 33.554348,\n",
       " 33.566845,\n",
       " 33.578659,\n",
       " 33.589825,\n",
       " 33.600334,\n",
       " 33.610199,\n",
       " 33.619431,\n",
       " 33.628021]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p[9] for p in pred_vals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check what happens if I do feed decoder inputs, and I do  train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_s_preds = [p[8] for p in pred_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1260d3630>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkYhToBcRiTgFehGRiFOgFxGJuP8Pm1aMOMykHvkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1260d3470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(last_s_preds)\n",
    "\n",
    "plt.plot([v_seq[8,i+1] for i in range(n_cond)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145063"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv('~/Downloads/median_smapes.csv')\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.04784536],\n",
       "       [-0.58076155],\n",
       "       [ 5.3185668 ],\n",
       "       [ 0.19689314],\n",
       "       [ 6.33993053],\n",
       "       [ 5.79123735],\n",
       "       [-9.02900887],\n",
       "       [ 0.57483214],\n",
       "       [-6.69227028],\n",
       "       [-5.93069601]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function basic_rnn_seq2seq in module tensorflow.contrib.legacy_seq2seq.python.ops.seq2seq:\n",
      "\n",
      "basic_rnn_seq2seq(encoder_inputs, decoder_inputs, cell, dtype=tf.float32, scope=None)\n",
      "    Basic RNN sequence-to-sequence model.\n",
      "    \n",
      "    This model first runs an RNN to encode encoder_inputs into a state vector,\n",
      "    then runs decoder, initialized with the last encoder state, on decoder_inputs.\n",
      "    Encoder and decoder use the same RNN cell type, but don't share parameters.\n",
      "    \n",
      "    Args:\n",
      "      encoder_inputs: A list of 2D Tensors [batch_size x input_size].\n",
      "      decoder_inputs: A list of 2D Tensors [batch_size x input_size].\n",
      "      cell: tf.nn.rnn_cell.RNNCell defining the cell function and size.\n",
      "      dtype: The dtype of the initial state of the RNN cell (default: tf.float32).\n",
      "      scope: VariableScope for the created subgraph; default: \"basic_rnn_seq2seq\".\n",
      "    \n",
      "    Returns:\n",
      "      A tuple of the form (outputs, state), where:\n",
      "        outputs: A list of the same length as decoder_inputs of 2D Tensors with\n",
      "          shape [batch_size x output_size] containing the generated outputs.\n",
      "        state: The state of each decoder cell in the final time-step.\n",
      "          It is a 2D Tensor of shape [batch_size x cell.state_size].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.legacy_seq2seq import basic_rnn_seq2seq\n",
    "help(basic_rnn_seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
