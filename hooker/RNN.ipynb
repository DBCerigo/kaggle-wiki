{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(base_dir+'train_1.csv', nrows=100)\n",
    "dates = [c for c in full_df.columns if c !='Page']\n",
    "val_dates = dates[-61:]\n",
    "val = full_df[['Page']+val_dates]\n",
    "train = full_df.drop(val_dates, axis=1)\n",
    "filled_train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = filled_train.drop('Page', axis=1).values\n",
    "y = val.fillna(0).drop('Page', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 489) (100, 61)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocessing\n",
    " * scale each time series to have 0 mean and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 489)\n",
      "(100, 489, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.010761664611856"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = StandardScaler()\n",
    "# discussion on which scaler to use here: https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/38274\n",
    "# each ts should have 0 mean and unit variance\n",
    "# since the time series are the 'features' being scaled, transpose first\n",
    "X = scaler.fit_transform(X.T).T\n",
    "print(X.shape)\n",
    "assert(np.isclose(np.mean(X[0]),0))\n",
    "# input shape: samples, timesteps, features\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "print(X.shape)\n",
    "np.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SEED = 123456\n",
    "n_pred = 60 # number of values to predict\n",
    "n_cond = 60 # number of values to condition on\n",
    "\n",
    "class DataProvider(object):\n",
    "    \"\"\"Generic data provider.\"\"\"\n",
    "\n",
    "    def __init__(self, inputs, targets, batch_size, max_num_batches=-1,\n",
    "                 shuffle_order=True, rng=None):\n",
    "        \"\"\"Create a new data provider object.\n",
    "\n",
    "        Args:\n",
    "            inputs (ndarray): Array of data input features of shape\n",
    "                (num_data, input_dim).\n",
    "            targets (ndarray): Array of data output targets of shape\n",
    "                (num_data, output_dim) or (num_data,) if output_dim == 1.\n",
    "            batch_size (int): Number of data points to include in each batch.\n",
    "            max_num_batches (int): Maximum number of batches to iterate over\n",
    "                in an epoch. If `max_num_batches * batch_size > num_data` then\n",
    "                only as many batches as the data can be split into will be\n",
    "                used. If set to -1 all of the data will be used.\n",
    "            shuffle_order (bool): Whether to randomly permute the order of\n",
    "                the data before each epoch.\n",
    "            rng (RandomState): A seeded random number generator.\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        if batch_size < 1:\n",
    "            raise ValueError('batch_size must be >= 1')\n",
    "        self._batch_size = batch_size\n",
    "        if max_num_batches == 0 or max_num_batches < -1:\n",
    "            raise ValueError('max_num_batches must be -1 or > 0')\n",
    "        self._max_num_batches = max_num_batches\n",
    "        self._update_num_batches()\n",
    "        self.shuffle_order = shuffle_order\n",
    "        self._current_order = np.arange(inputs.shape[0])\n",
    "        if rng is None:\n",
    "            rng = np.random.RandomState(DEFAULT_SEED)\n",
    "        self.rng = rng\n",
    "        self.new_epoch()\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        \"\"\"Number of data points to include in each batch.\"\"\"\n",
    "        return self._batch_size\n",
    "\n",
    "    @batch_size.setter\n",
    "    def batch_size(self, value):\n",
    "        if value < 1:\n",
    "            raise ValueError('batch_size must be >= 1')\n",
    "        self._batch_size = value\n",
    "        self._update_num_batches()\n",
    "\n",
    "    @property\n",
    "    def max_num_batches(self):\n",
    "        \"\"\"Maximum number of batches to iterate over in an epoch.\"\"\"\n",
    "        return self._max_num_batches\n",
    "\n",
    "    @max_num_batches.setter\n",
    "    def max_num_batches(self, value):\n",
    "        if value == 0 or value < -1:\n",
    "            raise ValueError('max_num_batches must be -1 or > 0')\n",
    "        self._max_num_batches = value\n",
    "        self._update_num_batches()\n",
    "\n",
    "    def _update_num_batches(self):\n",
    "        \"\"\"Updates number of batches to iterate over.\"\"\"\n",
    "        # maximum possible number of batches is equal to number of whole times\n",
    "        # batch_size divides in to the number of data points which can be\n",
    "        # found using integer division\n",
    "        possible_num_batches = self.inputs.shape[0] // self.batch_size\n",
    "        if self.max_num_batches == -1:\n",
    "            self.num_batches = possible_num_batches\n",
    "        else:\n",
    "            self.num_batches = min(self.max_num_batches, possible_num_batches)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Implements Python iterator interface.\n",
    "\n",
    "        This should return an object implementing a `next` method which steps\n",
    "        through a sequence returning one element at a time and raising\n",
    "        `StopIteration` when at the end of the sequence. Here the object\n",
    "        returned is the DataProvider itself.\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def new_epoch(self):\n",
    "        \"\"\"Starts a new epoch (pass through data), possibly shuffling first.\"\"\"\n",
    "        self._curr_batch = 0\n",
    "        if self.shuffle_order:\n",
    "            self.shuffle()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the provider to the initial state.\"\"\"\n",
    "        inv_perm = np.argsort(self._current_order)\n",
    "        self._current_order = self._current_order[inv_perm]\n",
    "        self.inputs = self.inputs[inv_perm]\n",
    "        self.targets = self.targets[inv_perm]\n",
    "        self.new_epoch()\n",
    "\n",
    "    def shuffle(self):\n",
    "        \"\"\"Randomly shuffles order of data.\"\"\"\n",
    "        perm = self.rng.permutation(self.inputs.shape[0])\n",
    "        self._current_order = self._current_order[perm]\n",
    "        self.inputs = self.inputs[perm]\n",
    "        self.targets = self.targets[perm]\n",
    "        if hasattr(self, 'track_ids'):\n",
    "            self.track_ids = self.track_ids[perm]\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"Returns next data batch or raises `StopIteration` if at end.\"\"\"\n",
    "        if self._curr_batch + 1 > self.num_batches:\n",
    "            # no more batches in current iteration through data set so start\n",
    "            # new epoch ready for another pass and indicate iteration is at end\n",
    "            self.new_epoch()\n",
    "            raise StopIteration()\n",
    "        # create an index slice corresponding to current batch number\n",
    "        batch_slice = slice(self._curr_batch * self.batch_size,\n",
    "                            (self._curr_batch + 1) * self.batch_size)\n",
    "        inputs_batch = self.inputs[batch_slice]\n",
    "        targets_batch = self.targets[batch_slice]\n",
    "        self._curr_batch += 1\n",
    "        return inputs_batch, targets_batch\n",
    "\n",
    "    # Python 3.x compatibility\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "class MultiTSDataProvider(DataProvider):\n",
    "    \n",
    "    def __init__(self, which_set='train', batch_size=100, max_num_batches=-1,\n",
    "                 shuffle_order=True, rng=None, n_pred=60, n_cond=60, stride_length=10,\n",
    "                 scaler=StandardScaler(), base_dir = '../data/', n_ts=100):\n",
    "        self.n_pred = n_pred # number of values to predict\n",
    "        self.n_cond = n_cond # number of values on which to condition predictions\n",
    "        full_df = pd.read_csv(base_dir+'train_1.csv', nrows=n_ts)\n",
    "        dates = [c for c in full_df.columns if c !='Page']\n",
    "        val_dates = dates[-(n_pred+n_cond):]\n",
    "        self.val_dates = val_dates\n",
    "        if which_set == 'train':\n",
    "            inputs = full_df.drop(['Page'] + val_dates, axis=1).fillna(0).values\n",
    "        elif which_set == 'val':\n",
    "            inputs = full_df[val_dates].fillna(0).values\n",
    "          # each ts should have 0 mean and unit variance\n",
    "        if scaler:\n",
    "            # need to change the way this behaves\n",
    "            inputs = scaler.fit_transform(inputs)\n",
    "            print(np.max(inputs))\n",
    "        print(inputs.shape)\n",
    "        \n",
    "        if which_set == 'train':\n",
    "            window_length = n_cond + n_pred\n",
    "            n_windows = int(np.floor(np.divide(inputs.shape[1] - window_length,\n",
    "                                               stride_length) + 1))\n",
    "            start_index = 0\n",
    "            window_array = np.ndarray((inputs.shape[0], n_windows, window_length))\n",
    "            for i in range(n_windows):\n",
    "                window_array[:,i,:] = inputs[:, start_index:start_index+window_length]\n",
    "                start_index += stride_length\n",
    "            print(window_array.shape)\n",
    "            window_array = window_array.reshape((-1,window_length,1))\n",
    "            print(window_array.shape)\n",
    "            print('{} overlapping windows of length {} in training date range'.format(n_windows, window_length))\n",
    "        #         inputs = w.reshape((-1, window_length, inputs.shape[-1])) # reshape inputs to (n_sample, length, n_features)\n",
    "            targets = window_array[:,self.n_cond:,:] # shifted one along from inputs - so there is one target val which is never input, into either decoder or encoder\n",
    "            inputs = np.pad(window_array[:,:-1,:],((0,0), (1,0), (0,0)),mode='constant')\n",
    "            \n",
    "        #         inputs, targets = inputs[:,:self.n_cond,:], inputs[:,self.n_cond:,:]\n",
    "            inputs = inputs.reshape((inputs.shape[0], -1))\n",
    "            targets = targets.reshape((targets.shape[0], -1))\n",
    "        \n",
    "        elif which_set == 'val':\n",
    "            targets = inputs[:, self.n_cond:]\n",
    "            inputs = np.pad(inputs[:,:self.n_cond], ((0,0), (1,n_pred-1)), mode='constant') # decoder inputs is now 1 useful num followed by a bunch of zeros, in principle\n",
    "        \n",
    "        print(inputs.shape, targets.shape)\n",
    "        super(MultiTSDataProvider, self).__init__(\n",
    "            inputs, targets, batch_size, max_num_batches, shuffle_order, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.86570145996\n",
      "(100, 430)\n",
      "(100, 32, 120)\n",
      "(3200, 120, 1)\n",
      "32 overlapping windows of length 120 in training date range\n",
      "(3200, 120) (3200, 60)\n",
      "(100, 120)\n",
      "(100, 120) (100, 60)\n",
      "example validation decoder input: \n",
      " [ 10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "train_data = MultiTSDataProvider(scaler=StandardScaler())\n",
    "val_data = MultiTSDataProvider(scaler=None, which_set='val')\n",
    "a = train_data.next()[0]\n",
    "np.max(a)\n",
    "b = val_data.next()[0]\n",
    "print('example validation decoder input: \\n', b[0][n_cond:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function:\n",
    "\n",
    "Modified SMAPE. Note that using MAE gives not much different results, but easier and faster to train, so I recommend MAE for starters. (https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/38337)\n",
    "\n",
    "### Output:\n",
    "\n",
    "You can predict one day, refit the model with previous days + predicted day, predict next day, etc, but it would be too slow and inefficient. The real power of RNN's is that you can build generative model, and predict all 60 days at once. (https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/38337)\n",
    "\n",
    "ONLY PREDICT VALUES FOR A SINGLE TIME SERIES AT ONCE (c.f. the neural network eqn. 1 which outputs hidden rnn states for a single time series at a time, which are then combined to form the joint likelihood above) - DIFFERENT TIME SERIES ARE USED TO GENERATE DIFFERENT TRAINING EXAMPLES; SINGLE MODEL IS TRAINED ON ALL OF THEM.\n",
    "\n",
    "a substantial amount\n",
    "of data on past behavior of similar, related time series can be leveraged for making a forecast for an\n",
    "individual time series. Using data from related time series not only allows fitting more complex (and\n",
    "hence potentially more accurate) models without overfitting\n",
    "\n",
    "https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n",
    "\n",
    "Simplest model is probably some kind of ar\n",
    "\n",
    "running predictions forward with keras: http://www.jakob-aungiers.com/articles/a/LSTM-Neural-Network-for-Time-Series-Prediction, https://machinelearningmastery.com/how-to-use-an-encoder-decoder-lstm-to-echo-sequences-of-random-integers/. the crucial thing that makes sequence to sequence appropriate is: Information about the observations in the conditioning range zi,1:t0−1 is transferred to the prediction\n",
    "range through the initial state hi,t0−1. In the sequence-to-sequence setup, this initial state is the output\n",
    "of an encoder network. Also the two sequences may be of different lengths.\n",
    "\n",
    "### Training examples\n",
    " \n",
    "Secondly, due to the imbalance in the data, a stochastic optimization procedure that picks training\n",
    "instances uniformly at random will visit the small number time series with a large scale very infrequently,\n",
    "which result in underfitting those time series. This could be especially problematic in the\n",
    "demand forecasting setting, where high-velocity items can exhibit qualitatively different behavior\n",
    "than low-velocity items, and having an accurate forecast for high-velocity items might be more important\n",
    "for meeting certain business objectives. To counteract this effect, we sample the examples\n",
    "non-uniformly during training. In particular, in our weighted sampling scheme, the probability of\n",
    "selecting a window from an example with scale νi is proportional to νi.\n",
    "\n",
    "### Tensorflow seq2seq\n",
    "[github seq2seq helpers](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py)\n",
    "[ex. model built using above](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py)\n",
    "[keras lib](https://github.com/farizrahman4u/seq2seq)\n",
    "[new api (1.3) seq2seq](https://medium.com/@ilblackdragon/tensorflow-sequence-to-sequence-3d9d2e238084)\n",
    "[seq2seq expts](https://github.com/raindeer/seq2seq_experiments/blob/master/model.py#L81)\n",
    "* use tied_rnn_seq2seq if using tf\n",
    "* will need to write custom loss func\n",
    "* not sure the keras library will work because although we are sort of using encoder-decoder, we're not really outputting a 'context vector', just transferring the hidden state\n",
    "* to pass predicted values in as inputs when decoding: https://stackoverflow.com/questions/38050333/how-to-predict-a-simple-sequence-using-seq2seq-from-tensorflow (although there is an option just to use the true values during training, which is what the amazon paper does).\n",
    "\n",
    "The initial state\n",
    "of the encoder hi,0 as well as zi,0 are initialized to zero\n",
    "\n",
    "The basic rnn seq2seq works by making a copy of the cell (set of lstm units), and using two separate copies, one for encoder and one for decoder, with different weights. Tied rnn seq2seq  uses a single copy, ensuring weights are shared.\n",
    "\n",
    "### Validation Data\n",
    "\n",
    "Should be normalized in the same way as training data (i.e. using statistics from the training data). But this doesn't really make sense - there's no shared features. So phaps just normalize validation inputs (not targets) in the same way that training inputs are normalized.\n",
    "\n",
    "The Amazon paper suggests scaling by the average value\n",
    "\n",
    "$v_i = 1  + \\sum_{t=0}^{t_0} z_{i,t}$\n",
    "\n",
    "where $t_0$ is the last conditioning timestep: i.e. we normalize on the conditioning period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.legacy_seq2seq import tied_rnn_seq2seq\n",
    "\n",
    "lstm_size = 100\n",
    "n_cond = 60\n",
    "n_pred = 60\n",
    "\n",
    "def compute_next_input(output, i):\n",
    "    p = tf.reshape(tf.matmul(output, weights), (-1,)) + bias\n",
    "    return tf.reshape(p,(-1,1))\n",
    "\n",
    "def decoder_init(input_list, n_pred):\n",
    "    for i in range(n_pred):\n",
    "        input_list.append(tf.placeholder(tf.float32, shape=[None,1], name=\"decoder{0}\".format(i)))\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    encoder_inputs = []\n",
    "    decoder_inputs = []\n",
    "    targets = []\n",
    "    for i in range(n_cond):\n",
    "        # individual inputs are single numbers \n",
    "        encoder_inputs.append(tf.placeholder(tf.float32, shape=[None,1], name=\"encoder{0}\".format(i)))\n",
    "    for i in range(n_pred):\n",
    "        decoder_inputs.append(tf.placeholder(tf.float32, shape=[None,1], name=\"decoder{0}\".format(i)))\n",
    "    for i in range(n_pred):\n",
    "        targets.append(tf.placeholder(tf.float32, shape=[None], name=\"target{0}\".format(i)))\n",
    "    train = tf.placeholder(tf.bool)\n",
    "    bias = tf.Variable(initial_value=1.0)\n",
    "    weights = tf.Variable(tf.truncated_normal(\n",
    "            [lstm_size, 1], stddev=2. / (lstm_size + 1)**0.5), \n",
    "        'weights')\n",
    "    def looper(output, i):\n",
    "        return tf.reshape(tf.reshape(tf.matmul(output, weights), (-1,)) + bias, (-1,1))\n",
    "#     targets = [decoder_inputs[i+1] for i in range(len(decoder_inputs)-1)] # targets are next inputs\n",
    "    # could use sthg like tf.cond: https://www.tensorflow.org/versions/r0.12/api_docs/python/control_flow_ops/control_flow_operations\n",
    "    # to determine whether or not to use a loop function\n",
    "    \n",
    "    outputs, states = tf.cond(train, lambda: tied_rnn_seq2seq(encoder_inputs, decoder_inputs, cell),\n",
    "                              lambda: tied_rnn_seq2seq(encoder_inputs, decoder_inputs, cell, loop_function=looper))\n",
    "#     outputs, states = tf.contrib.legacy_seq2seq.tied_rnn_seq2seq(encoder_inputs, decoder_inputs, cell)\n",
    "    # to do val, need to define a loop function\n",
    "    # outputs is a list where each thing has shape (batch_size,n_lstm)\n",
    "    # loop_function will need to apply a linear transform\n",
    "    preds = []\n",
    "    losses = []\n",
    "    for output, target in zip(outputs, targets):\n",
    "#         weights = tf.Variable(tf.ones([lstm_size,1]))\n",
    "        pred = tf.reshape(tf.matmul(output, weights), (-1,)) + bias\n",
    "        preds.append(pred) # each pred is shape [batch_size]\n",
    "        losses.append(tf.reduce_mean(tf.abs(pred-target))) # error for a given output position averaged over the batch\n",
    "    \n",
    "    mae = tf.reduce_mean(losses) # compute error averaged over the timesteps (and batch samples)\n",
    "#     mae = tf.metrics.mean_absolute_error(targets, outputs)\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=0.01).minimize(mae)\n",
    "    init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    }
   ],
   "source": [
    "print('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 430)\n",
      "(100, 32, 120)\n",
      "(3200, 120, 1)\n",
      "32 overlapping windows of length 120 in training date range\n",
      "(3200, 120) (3200, 60)\n",
      "(100, 430)\n",
      "(100, 32, 120)\n",
      "(3200, 120, 1)\n",
      "32 overlapping windows of length 120 in training date range\n",
      "(3200, 120) (3200, 60)\n",
      "End of epoch 1: running error average = 12.883\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.742\n",
      "End of epoch 2: running error average = 10.601\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.548\n",
      "End of epoch 3: running error average = 10.256\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.468\n",
      "End of epoch 4: running error average = 10.115\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.832\n",
      "End of epoch 5: running error average = 10.016\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.327\n",
      "End of epoch 6: running error average = 9.936\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.295\n",
      "End of epoch 7: running error average = 9.908\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.213\n",
      "End of epoch 8: running error average = 9.856\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.580\n",
      "End of epoch 9: running error average = 9.838\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.562\n",
      "End of epoch 10: running error average = 9.774\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.336\n",
      "End of epoch 11: running error average = 9.757\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.160\n",
      "End of epoch 12: running error average = 9.736\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.173\n",
      "End of epoch 13: running error average = 9.723\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.046\n",
      "End of epoch 14: running error average = 9.676\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 10.958\n",
      "End of epoch 15: running error average = 9.677\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.164\n",
      "End of epoch 16: running error average = 9.657\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.211\n",
      "End of epoch 17: running error average = 9.631\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.014\n",
      "End of epoch 18: running error average = 9.615\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.068\n",
      "End of epoch 19: running error average = 9.591\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.203\n",
      "End of epoch 20: running error average = 9.572\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.110\n",
      "End of epoch 21: running error average = 9.559\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.016\n",
      "End of epoch 22: running error average = 9.546\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.161\n",
      "End of epoch 23: running error average = 9.523\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.074\n",
      "End of epoch 24: running error average = 9.485\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.255\n",
      "End of epoch 25: running error average = 9.452\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.067\n",
      "End of epoch 26: running error average = 9.416\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.164\n",
      "End of epoch 27: running error average = 9.391\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.084\n",
      "End of epoch 28: running error average = 9.371\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 10.975\n",
      "End of epoch 29: running error average = 9.361\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.050\n",
      "End of epoch 30: running error average = 9.314\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 10.999\n",
      "End of epoch 31: running error average = 9.275\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.187\n",
      "End of epoch 32: running error average = 9.260\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 10.979\n",
      "End of epoch 33: running error average = 9.225\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.109\n",
      "End of epoch 34: running error average = 9.170\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.026\n",
      "End of epoch 35: running error average = 9.139\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.242\n",
      "End of epoch 36: running error average = 9.111\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.000\n",
      "End of epoch 37: running error average = 9.050\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 10.965\n",
      "End of epoch 38: running error average = 8.975\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.068\n",
      "End of epoch 39: running error average = 8.962\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.017\n",
      "End of epoch 40: running error average = 8.949\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.160\n",
      "End of epoch 41: running error average = 8.882\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.175\n",
      "End of epoch 42: running error average = 8.886\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.106\n",
      "End of epoch 43: running error average = 8.929\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.280\n",
      "End of epoch 44: running error average = 8.790\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.070\n",
      "End of epoch 45: running error average = 8.759\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.162\n",
      "End of epoch 46: running error average = 8.765\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.136\n",
      "End of epoch 47: running error average = 8.698\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.048\n",
      "End of epoch 48: running error average = 8.653\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.150\n",
      "End of epoch 49: running error average = 8.628\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.266\n",
      "End of epoch 50: running error average = 8.614\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.430\n",
      "End of epoch 51: running error average = 8.686\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.213\n",
      "End of epoch 52: running error average = 8.612\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.201\n",
      "End of epoch 53: running error average = 8.536\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.400\n",
      "End of epoch 54: running error average = 8.540\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.178\n",
      "End of epoch 55: running error average = 8.519\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.175\n",
      "End of epoch 56: running error average = 8.494\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.217\n",
      "End of epoch 57: running error average = 8.460\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.677\n",
      "End of epoch 58: running error average = 8.437\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.439\n",
      "End of epoch 59: running error average = 8.439\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.154\n",
      "End of epoch 60: running error average = 8.401\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.257\n",
      "End of epoch 61: running error average = 8.377\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.357\n",
      "End of epoch 62: running error average = 8.457\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 63: running error average = 8.392\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.208\n",
      "End of epoch 64: running error average = 8.343\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.243\n",
      "End of epoch 65: running error average = 8.326\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.408\n",
      "End of epoch 66: running error average = 8.273\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.370\n",
      "End of epoch 67: running error average = 8.355\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.255\n",
      "End of epoch 68: running error average = 8.299\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.156\n",
      "End of epoch 69: running error average = 8.233\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.141\n",
      "End of epoch 70: running error average = 8.213\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.277\n",
      "End of epoch 71: running error average = 8.173\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.477\n",
      "End of epoch 72: running error average = 8.263\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.237\n",
      "End of epoch 73: running error average = 9.518\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.302\n",
      "End of epoch 74: running error average = 9.484\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.313\n",
      "End of epoch 75: running error average = 9.275\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.146\n",
      "End of epoch 76: running error average = 9.151\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.505\n",
      "End of epoch 77: running error average = 9.076\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.072\n",
      "End of epoch 78: running error average = 8.949\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.284\n",
      "End of epoch 79: running error average = 8.962\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.469\n",
      "End of epoch 80: running error average = 9.301\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.335\n",
      "End of epoch 81: running error average = 9.131\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.521\n",
      "End of epoch 82: running error average = 9.011\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.169\n",
      "End of epoch 83: running error average = 8.918\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.128\n",
      "End of epoch 84: running error average = 8.848\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.148\n",
      "End of epoch 85: running error average = 8.755\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.224\n",
      "End of epoch 86: running error average = 8.741\n",
      "\n",
      "             mean error average = 12.147\n",
      "\n",
      "             val error average = 11.194\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-5f25b5503a78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0merrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mmean_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_cond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexhooker/projects/informatics/py3env/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexhooker/projects/informatics/py3env/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexhooker/projects/informatics/py3env/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexhooker/projects/informatics/py3env/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexhooker/projects/informatics/py3env/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_ts = 100\n",
    "train_data = MultiTSDataProvider(n_ts=n_ts, scaler=None)\n",
    "val_data = MultiTSDataProvider(n_ts=n_ts, scaler=None)\n",
    "\n",
    "sess = tf.Session(graph=graph)\n",
    "sess.run(init_op)\n",
    "errs = []\n",
    "epochs = 100\n",
    "for e in range(epochs):\n",
    "    running_error = 0.\n",
    "    val_error = 0.\n",
    "    mean_running_error = 0.\n",
    "    for input_batch, target_batch in train_data:\n",
    "    #     print(input_batch.shape, target_batch.shape)\n",
    "        feed_dict = {train: True}\n",
    "        # each decoder input is batch size x 1\n",
    "        for i in range(n_cond):\n",
    "            feed_dict[encoder_inputs[i].name] = input_batch[:,i].reshape(-1,1)\n",
    "        for i in range(n_pred):\n",
    "            feed_dict[decoder_inputs[i].name] = input_batch[:,n_cond+i].reshape(-1,1)\n",
    "        for i in range(n_pred):\n",
    "            feed_dict[targets[i].name] = target_batch[:,i]\n",
    "        _, err, predictions = sess.run([train_step, mae, preds], feed_dict=feed_dict)\n",
    "        errs.append(err)\n",
    "        mean_preds = np.mean(input_batch[:,:n_cond], axis=1).reshape(-1,1)\n",
    "#         print(mean_preds.shape, target_batch.shape)\n",
    "        mean_errs = np.abs(mean_preds - target_batch)\n",
    "#         print(mean_errs.shape)\n",
    "        batch_mean_err = np.mean(mean_errs)\n",
    "        running_error += err\n",
    "        mean_running_error += batch_mean_err\n",
    "    running_error /= train_data.num_batches\n",
    "    mean_running_error /= train_data.num_batches\n",
    "    for input_batch, target_batch in val_data:\n",
    "        feed_dict = {train: False}\n",
    "        for i in range(n_cond):\n",
    "            feed_dict[encoder_inputs[i].name] = input_batch[:,i].reshape(-1,1)\n",
    "        for i in range(n_pred):\n",
    "            feed_dict[targets[i].name] = target_batch[:,i]\n",
    "        for i in range(n_pred):\n",
    "            feed_dict[decoder_inputs[i].name] = input_batch[:,n_cond+i].reshape(-1,1)\n",
    "        val_err = sess.run(mae, feed_dict=feed_dict)\n",
    "        # this time we don't need to feed in either decoder_inputs or targets\n",
    "        val_error += val_err\n",
    "    val_error /= val_data.num_batches\n",
    "    print(\"\"\"End of epoch {0}: running error average = {1:.3f}\\n\n",
    "             mean error average = {2:.3f}\\n\n",
    "             val error average = {3:.3f}\"\"\".format(e + 1, running_error, mean_running_error, val_error))\n",
    "# print(len(preds), preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sanity check:\n",
    "\n",
    " * Look at (plot) trained model's predictions from a few out of training sample time series (compare plot after just training on one batch to after a full training run).\n",
    "\n",
    "* Look at SMAPE on val set\n",
    "\n",
    "(NOT GOOD IDEA: Plot multiple sets of predictions for a single time series to verify that the RNN is acting as a generative model in a sensible (random) way - NO THE CURRENT MODEL IS DETERMINISTIC, TO MAKE A PROBABILISTIC MODEL I WOULD HAVE TO OUTPUT PROBABILITIES/PARAMETERS OF A PROBABILITY DISTRIBUTION RATHER THAN ACTUAL VALUES.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
