{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../')\n",
    "from wiki.utils import clock\n",
    "from wiki import rnn, rnn_predict, newphet, val, submissions\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "pred_len = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = '../data/'\n",
    "train_df = pd.read_csv(base_dir+'train_1.csv').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_df.drop('Page', axis=1).values\n",
    "X, scaler = rnn.scale_values(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all the data to train this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainloader = data_utils.DataLoader(\n",
    "    data_utils.TensorDataset(\n",
    "        torch.from_numpy(X[:,:-pred_len,:]).float(),\n",
    "        torch.from_numpy(X[:,-pred_len:,:]).float()\n",
    "    ),\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its crucial that the `testloader` is not shuffled, as we'll use the page names directly from the train csv to index them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testloader = data_utils.DataLoader(\n",
    "    data_utils.TensorDataset(\n",
    "        torch.from_numpy(X[:,:,:]).float(),\n",
    "        torch.zeros(X.shape[0], pred_len, X.shape[2])\n",
    "    ),\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_func = nn.L1Loss()\n",
    "model = rnn.RNN(loss_func=loss_func).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epochs chosen by amount of epochs to best val loss on validated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1\n",
      "Running average loss: 0.435974\n",
      "Elapsed time 132.3519835472107 seconds\n",
      "\n",
      "EPOCH 2\n",
      "Running average loss: 0.403352\n",
      "Elapsed time 105.45952820777893 seconds\n",
      "\n",
      "EPOCH 3\n",
      "Running average loss: 0.415883\n",
      "Elapsed time 106.2205502986908 seconds\n",
      "\n",
      "EPOCH 4\n",
      "Running average loss: 0.384447\n",
      "Elapsed time 107.26095294952393 seconds\n",
      "\n",
      "EPOCH 5\n",
      "Running average loss: 0.384038\n",
      "Elapsed time 107.32022714614868 seconds\n",
      "\n",
      "EPOCH 6\n",
      "Running average loss: 0.393268\n",
      "Elapsed time 107.60648727416992 seconds\n",
      "\n",
      "EPOCH 7\n",
      "Running average loss: 0.403062\n",
      "Elapsed time 107.50295424461365 seconds\n",
      "\n",
      "EPOCH 8\n",
      "Running average loss: 0.386139\n",
      "Elapsed time 107.26458477973938 seconds\n",
      "\n",
      "EPOCH 9\n",
      "Running average loss: 0.376185\n",
      "Elapsed time 107.23961544036865 seconds\n",
      "\n",
      "EPOCH 10\n",
      "Running average loss: 0.395370\n",
      "Elapsed time 107.49779915809631 seconds\n",
      "\n",
      "EPOCH 11\n",
      "Running average loss: 0.373344\n",
      "Elapsed time 107.35019207000732 seconds\n",
      "\n",
      "EPOCH 12\n",
      "Running average loss: 0.372232\n",
      "Elapsed time 107.40108442306519 seconds\n",
      "\n",
      "EPOCH 13\n",
      "Running average loss: 0.382426\n",
      "Elapsed time 107.42419791221619 seconds\n",
      "\n",
      "EPOCH 14\n",
      "Running average loss: 0.374511\n",
      "Elapsed time 107.40211343765259 seconds\n",
      "\n",
      "EPOCH 15\n",
      "Running average loss: 0.383623\n",
      "Elapsed time 107.48527336120605 seconds\n",
      "\n",
      "EPOCH 16\n",
      "Running average loss: 0.359450\n",
      "Elapsed time 107.33251619338989 seconds\n",
      "\n",
      "EPOCH 17\n",
      "Running average loss: 0.370011\n",
      "Elapsed time 107.16671967506409 seconds\n",
      "\n",
      "EPOCH 18\n",
      "Running average loss: 0.378717\n",
      "Elapsed time 107.8409960269928 seconds\n",
      "Elapsed time 1955.1342017650604 seconds\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "with clock():\n",
    "    model.fit(trainloader, None, optimizer=optimizer, num_epochs=18)\n",
    "save_best_path = base_dir+'rnn_v2_predictor_lr1_weights.mdl'\n",
    "torch.save(model.state_dict(), save_best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1\n",
      "Running average loss: 0.371828\n",
      "Elapsed time 107.35065841674805 seconds\n",
      "\n",
      "EPOCH 2\n",
      "Running average loss: 0.366410\n",
      "Elapsed time 107.13260817527771 seconds\n",
      "\n",
      "EPOCH 3\n",
      "Running average loss: 0.360923\n",
      "Elapsed time 107.18335103988647 seconds\n",
      "\n",
      "EPOCH 4\n",
      "Running average loss: 0.353547\n",
      "Elapsed time 107.15616416931152 seconds\n",
      "\n",
      "EPOCH 5\n",
      "Running average loss: 0.364152\n",
      "Elapsed time 107.2029218673706 seconds\n",
      "\n",
      "EPOCH 6\n",
      "Running average loss: 0.363673\n",
      "Elapsed time 107.23570728302002 seconds\n",
      "\n",
      "EPOCH 7\n",
      "Running average loss: 0.364665\n",
      "Elapsed time 107.27262473106384 seconds\n",
      "\n",
      "EPOCH 8\n",
      "Running average loss: 0.354986\n",
      "Elapsed time 107.22689461708069 seconds\n",
      "Elapsed time 857.7650198936462 seconds\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "with clock():\n",
    "    model.fit(trainloader, None, optimizer=optimizer, num_epochs=8)\n",
    "save_best_path = base_dir+'rnn_v2_predictor_lr2_weights.mdl'\n",
    "torch.save(model.state_dict(), save_best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_best_path = base_dir+'rnn_v2_predictor_lr2_weights.mdl'\n",
    "#loss_func = nn.L1Loss()\n",
    "#model = rnn.RNN(loss_func=loss_func).cuda()\n",
    "#model.load_state_dict(torch.load(save_best_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, targets, sequences = model.predict(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = scaler.inverse_transform(outputs.data.cpu().numpy().squeeze().T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.08768597e+01,   2.06833591e+01,   2.01083450e+01, ...,\n",
       "          2.27052174e+01,   2.24966240e+01,   2.23551865e+01],\n",
       "       [  2.13238945e+01,   2.04893436e+01,   2.20704422e+01, ...,\n",
       "          2.20366802e+01,   2.29790096e+01,   2.40018997e+01],\n",
       "       [  7.81798315e+00,   5.79528189e+00,   5.54005861e+00, ...,\n",
       "          4.86465740e+00,   4.68661642e+00,   4.54093695e+00],\n",
       "       ..., \n",
       "       [ -1.26851350e-03,  -1.82658434e-03,  -2.10051611e-03, ...,\n",
       "         -9.74615663e-03,  -9.88163427e-03,  -9.98216122e-03],\n",
       "       [ -1.26851350e-03,  -1.82658434e-03,  -2.10051611e-03, ...,\n",
       "         -9.74615663e-03,  -9.88163427e-03,  -9.98216122e-03],\n",
       "       [ -1.26851350e-03,  -1.82658434e-03,  -2.10051611e-03, ...,\n",
       "         -9.74615663e-03,  -9.88163427e-03,  -9.98216122e-03]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = '../data/submissions/rnn_v2.csv'\n",
    "submissions.write_submission(predictions, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
