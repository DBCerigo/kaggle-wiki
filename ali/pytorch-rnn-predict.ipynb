{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import pickle as pkl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "sys.path.append('../')\n",
    "from wiki.utils import clock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(base_dir+'train_1.csv').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.drop('Page', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145063, 550)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = X.shape ; shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X.T).T\n",
    "print(X.shape)\n",
    "assert(np.isclose(np.mean(X[0]),0))\n",
    "# input shape: samples, timesteps, features\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "print(X.shape)\n",
    "np.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145063, 550)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.1, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unsqueeze below is adding another dimension to the tensors (size 1, at the end). Also I believe the shuffle only shuffles the first dimension (thus shuffling the sequences whole). This could also probably be turned off with no ill effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valloader = data_utils.DataLoader(\n",
    "    data_utils.TensorDataset(\n",
    "        torch.from_numpy(X_test).float().unsqueeze(-1)\n",
    "    ),\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testloader = data_utils.DataLoader(\n",
    "    data_utils.TensorDataset(\n",
    "        torch.from_numpy(X[:,:-60]).float().unsqueeze(-1)\n",
    "    ),\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_units = 128\n",
    "        self.n_layers = 2\n",
    "        \n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=1,\n",
    "            hidden_size=self.hidden_units,\n",
    "            num_layers=self.n_layers, #number of RNN layers\n",
    "            batch_first=True, #batch dimension is first\n",
    "            #nonlinearity='relu',\n",
    "            dropout=0.2\n",
    "        )\n",
    "\n",
    "        #I can change the below to two softplus outputs for\n",
    "        #mean and variance in the paper version (see notes below)\n",
    "        self.out = nn.Linear(self.hidden_units, 1)\n",
    "        \n",
    "    def forward(self, x, h_state):\n",
    "        # dimensions:\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "        r_out, h_state = self.rnn(x, h_state)\n",
    "        return self.out(r_out), h_state\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, batch_size, self.hidden_units)).cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(model, valloader, pred_date_len):\n",
    "    loss_func = nn.MSELoss()\n",
    "    loss = 0\n",
    "    for data_all in valloader:\n",
    "        sequences = data_all[:,:-pred_date_len,:]\n",
    "        targets = Variable(data_all[:,-pred_date_len:,:], volatile=True).cuda()\n",
    "        output = predict_batch(model, sequences, pred_date_len)\n",
    "        loss += loss_func(output, targets)\n",
    "    return loss.data[0]/length\n",
    "    print('Val loss, %f' % float(loss.data[0])/pred_date_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_batch(model, batch, pred_date_len):\n",
    "    output = []\n",
    "    h_state = model.init_hidden(batch.size()[0])\n",
    "    x=Variable(batch, volatile=True).cuda()\n",
    "    encoder_out, h_state = model(x, h_state)\n",
    "\n",
    "    input_variable = encoder_out[:,-1:,:]\n",
    "    output.append(input_variable)\n",
    "    for i in range(pred_date_len-1):\n",
    "        encoder_out, h_state = model(input_variable, h_state)\n",
    "        input_variable = encoder_out\n",
    "        output.append(encoder_out)\n",
    "    \n",
    "    return torch.cat(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader, pred_date_len):\n",
    "    all_output = []\n",
    "    for data_all in dataloader:\n",
    "        output = predict_batch(model, data_all, pred_date_len)\n",
    "        all_output.append(output)\n",
    "    return torch.cat(all_output, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is borrowed from some bloke on the discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('rnn.pkl')\n",
    "for p in model.parameters():\n",
    "    pass\n",
    "    #p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/basev1/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    }
   ],
   "source": [
    "loss = validate(model, valloader, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.087971845166369e-08"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/basev1/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    }
   ],
   "source": [
    "with clock():\n",
    "    predictions = predict(model, testloader, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = predictions.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.reshape(sc.inverse_transform(np.reshape(predictions.cpu().data.numpy(),(-1,1))), shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1291.57189941],\n",
       "       [-1287.5291748 ],\n",
       "       [-1282.36621094],\n",
       "       [-1277.69030762],\n",
       "       [-1273.59887695],\n",
       "       [-1270.38415527],\n",
       "       [-1267.90014648],\n",
       "       [-1265.95178223],\n",
       "       [-1264.6854248 ],\n",
       "       [-1263.37036133],\n",
       "       [-1262.49365234],\n",
       "       [-1261.90917969],\n",
       "       [-1261.27600098],\n",
       "       [-1260.83752441],\n",
       "       [-1260.6427002 ],\n",
       "       [-1260.35046387],\n",
       "       [-1260.00952148],\n",
       "       [-1259.91210938],\n",
       "       [-1259.71728516],\n",
       "       [-1259.52246094],\n",
       "       [-1259.52246094],\n",
       "       [-1259.52246094],\n",
       "       [-1259.47375488],\n",
       "       [-1259.37634277],\n",
       "       [-1259.32763672],\n",
       "       [-1259.32763672],\n",
       "       [-1259.23022461],\n",
       "       [-1259.1328125 ],\n",
       "       [-1259.1328125 ],\n",
       "       [-1259.1328125 ],\n",
       "       [-1259.1328125 ],\n",
       "       [-1259.1328125 ],\n",
       "       [-1259.08410645],\n",
       "       [-1258.98669434],\n",
       "       [-1258.98669434],\n",
       "       [-1258.98669434],\n",
       "       [-1258.98669434],\n",
       "       [-1259.03540039],\n",
       "       [-1258.93798828],\n",
       "       [-1258.93798828],\n",
       "       [-1259.03540039],\n",
       "       [-1258.93798828],\n",
       "       [-1258.93798828],\n",
       "       [-1258.93798828],\n",
       "       [-1258.93798828],\n",
       "       [-1259.03540039],\n",
       "       [-1258.93798828],\n",
       "       [-1258.93798828],\n",
       "       [-1258.93798828],\n",
       "       [-1258.93798828],\n",
       "       [-1258.88928223],\n",
       "       [-1258.88928223],\n",
       "       [-1258.88928223],\n",
       "       [-1258.88928223],\n",
       "       [-1258.88928223],\n",
       "       [-1258.88928223],\n",
       "       [-1258.88928223],\n",
       "       [-1258.88928223],\n",
       "       [-1258.88928223],\n",
       "       [-1258.88928223]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[400,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.67601257e-07,   3.71668413e-07,   2.08134311e-07,\n",
       "         2.97334730e-07,   1.18933892e-07,   9.96071346e-07,\n",
       "         1.93267575e-07,   6.09536197e-07,   1.48667365e-07,\n",
       "         3.12201467e-07,   1.93267575e-07,   1.18933892e-07,\n",
       "         2.23001048e-07,   2.08134311e-07,   1.78400838e-07,\n",
       "         8.92004190e-08,   1.63534102e-07,   1.48667365e-07,\n",
       "         6.24402933e-07,   3.12201467e-07,   3.56801676e-07,\n",
       "         2.08134311e-07,   1.63534102e-07,   3.03281425e-06,\n",
       "         2.08134311e-07,   6.69003143e-07,   4.90602305e-07,\n",
       "         4.16268622e-07,   2.67601257e-07,   2.08134311e-07,\n",
       "         6.98736616e-07,   2.23001048e-07,   2.08134311e-07,\n",
       "         2.67601257e-07,   2.97334730e-07,   2.08134311e-07,\n",
       "         2.37867784e-07,   2.08134311e-07,   2.97334730e-07,\n",
       "         8.92004190e-07,   3.27068203e-07,   2.23001048e-07,\n",
       "         2.52734521e-07,   2.82467994e-07,   2.67601257e-07,\n",
       "         3.12201467e-07,   3.12201467e-07,   6.98736616e-07,\n",
       "         9.66337873e-07,   2.52734521e-07,   4.75735568e-07,\n",
       "         9.36604400e-07,   2.23001048e-07,   3.86535149e-07,\n",
       "         2.08134311e-07,   2.97334730e-07,   3.27068203e-07,\n",
       "         2.82467994e-07,   2.67601257e-07,   2.97334730e-07])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0,-60:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
